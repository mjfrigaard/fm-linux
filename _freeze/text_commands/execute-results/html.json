{
  "hash": "16f7a403d9fdbe40fb851b4f537cb225",
  "result": {
    "engine": "knitr",
    "markdown": "---\nengine: knitr\nknitr:\n  opts_chunk: \n    collapse: true\n---\n\n\n\n\n# Text Commands {#sec-txt-cmds .unnumbered}\n\n\n\n\n\n\n\n\n\n:::: {.callout-important collapse='false' appearance='default' icon=false}\n\n## [Caution]{style='font-weight: bold; font-size: 1.25em;'}\n\n::: {style='font-size: 1.00em; color: #282b2d;'}\n\n\nThis section is under development. Thank you for your patience.\n  \n\n::: \n\n::::\n\n\n\n\nThe Unix and Linux operating systems thrive on simplicity and efficiency, principles elegantly manifested in text handling. Central to this ecosystem are the commands explicitly designed for text manipulation—tools such as `cat`, `sort`, `cut`, and others form the core of text processing activities.\n\n### The Text Stream\n\nUnix/Linux conceptualizes text as a stream, a continuous sequence of characters that can be manipulated in real-time. Streams are crucial for understanding how Unix/Linux commands process text. A text stream can originate from files, input devices, or even the output of other commands. Treating text as a steady stream of inputs offers a versatile and powerful method for text manipulation.\n\n\n<!--\n\n- **`cat`**: Beyond simply displaying the content of files, `cat` is often used to concatenate several text files into one and to work with text streams.\n- **`sort`**: As the name suggests, `sort` organizes text lines into a specified order, proving invaluable for data analysis and organization tasks.\n- **`cut`**: This command extracts sections from each line of input, making it essential for parsing and processing delimited data.\n- **`grep`**: A powerful search tool, `grep` filters text according to patterns, enabling complex data extraction and analysis operations.\n- **`awk`**: An entire programming language in itself, `awk` is designed for pattern scanning and processing, offering sophisticated text manipulation capabilities.\n- **`sed`**: The stream editor (`sed`) transforms text in a stream, allowing for powerful pattern matching and substitution.\n\nEach of these commands leverages stdin and stdout, enabling them to be combined in pipelines that filter, transform, and manipulate text in complex ways with just a few keystrokes. This section aims to demystify these commands, providing a foundation for understanding and utilizing Unix's rich text manipulation capabilities.\n\nBy mastering these commands, you gain the ability to effortlessly manipulate text streams, transforming raw data into structured information. This knowledge is not just a technical skill but a gateway to the deeper philosophy of Unix, where simplicity and efficiency reign supreme.\n-->\n\n## Text Manipulation {#sec-txt-manip .unnumbered}\n\nThese commands embody the Unix philosophy of '*do one thing and do it well*' and demonstrate the system’s power in processing text streams. This section will explore these fundamental commands, illustrating how they easily interact with text streams, standard input (`stdin`), and standard output (`stdout`) to perform complex text manipulations.\n\n\n\n\n\n:::: {.callout-tip collapse='true' appearance='default' icon=false}\n\n## [Standard Input and Output]{style='font-weight: bold; font-size: 1.25em;'}\n\n::: {style='font-size: 1.00em; color: #282b2d;'}\n\n\n\n\n`stdin` (standard input) is a stream from which a command reads its input. By default, it's the keyboard, but it can be redirected to read from a file or another command's output.\n\n  \n![The text stream looks nothing like this](img/mr-robot.gif){fig-align='center' width='75%'}\n  \n`stdout` (standard output) is a stream where a command writes its output. Typically, this is the terminal screen, but it can be redirected to a file or another command's input.\n\n\n::: \n\n::::\n\n\n\n\n### `cat` {#sec-cat}\n\n**`cat` (Concatenate)**: `cat` displays the content of files straight to your screen, useful for checking what's in a text file quickly.\n\nThis is similar to printing a file and laying out the pages on the floor to see them all at once.\n\n### `grep` {#sec-grep}\n\n**`grep`** stands for \"global regular expression print\" and it reads from `stdin` or a list of files and outputs the lines that contain matches for a specified pattern.\n\n\n### `sort` {#sec-sort}\n\n**`sort`**: `sort` arranges the lines in a text file into order:\n\n\nSimilar to organizing our stack of papers alphabetically.\n\n### `uniq` {#sec-uniq}\n\n**`uniq`**: `uniq` helps by removing duplicate lines from a file, making sure every line is unique.\n\n\nAfter accidentally printing duplicates of a document, you remove the extra copies.\n\n### `cut` {#sec-cut}\n\n**`cut`**: If you only want the dates from a list of events, you might physically cut them out of the paper. `cut` extracts specific parts of lines in a file, like cutting out columns of text.\n\n### `paste` {#sec-paste}\n\n**`paste`**: Taking snippets of text from different documents and sticking them together into one, `paste` combines lines from multiple files side by side.\n\n### `join` {#sec-join}\n\n**`join`**: If you have two lists with common information, you might merge them based on what matches. `join` merges lines from two files based on a common field.\n\n### `comm` {#sec-comm}\n\n**`comm` (Compare)**: Laying two printed lists side by side to see what items appear on both, only on one, or the other, `comm` compares two sorted files line by line.\n\n### `diff` {#sec-diff}\n\n**`diff` (Difference)**: Highlighting what changes have been made between your draft and the final copy of a letter, `diff` shows the differences between two files.\n\nThese analogies help demystify what can feel like complex commands, tying them back to everyday actions and decisions.\n\n\n\n\n\n\n:::: {.callout-note collapse='false' appearance='default' icon=false}\n\n## [See a typo, error, or something missing?]{style='font-weight: bold; font-size: 0.95em;'}\n\n::: {style='font-size: 0.90em; color: #282b2d;'}\n\n\nPlease open an issue on [GitHub.](https://github.com/mjfrigaard/fm-unix/issues/new)\n\n::: \n\n::::",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}