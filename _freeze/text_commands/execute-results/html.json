{
  "hash": "e1d78f4622d47a3c3fbf47b123cbbba2",
  "result": {
    "engine": "knitr",
    "markdown": "---\nengine: knitr\nknitr:\n  opts_chunk: \n    collapse: true\n    comment: '#'\n---\n\n\n\n\n\n# Manipulating Text {#sec-txt-cmds}\n\n\n\n\n\n\n\n\n\n\n:::: {.callout-important collapse='false' appearance='default' icon=false}\n\n## [Caution]{style='font-weight: bold; font-size: 1.25em;'}\n\n::: {style='font-size: 1.00em; color: #282b2d;'}\n\n\nThis section is under development. Thank you for your patience.\n  \n\n::: \n\n::::\n\n\n\n\n\nThe Unix and Linux operating systems thrive on simplicity and efficiency, principles elegantly manifested in text handling. Central to this ecosystem are the commands explicitly designed for text manipulation.\n\n## The Text Stream\n\nUnix/Linux conceptualizes text as a stream, a continuous sequence of characters that can be manipulated in real-time. Streams are crucial for understanding how Unix/Linux commands process text. A text stream can originate from files, input devices, or even the output of other commands. Treating text as a steady stream of inputs offers a versatile and powerful method for text manipulation.\n\n\n\n\n\n\n:::: {.callout-note collapse='true' appearance='default' icon=false}\n\n## [ Refresher: Standard Input and Standard Output]{style='font-weight: bold; font-size: 1.10em;'}\n\n::: {style='font-size: 1.05em; color: #282b2d;'}\n\n\nTwo key concepts in Unix text processing are standard input (`stdin`) and standard output (`stdout`). `stdin` is the default input stream, which often comes from the keyboard or the output of another command. `stdout` is the default output stream, typically the terminal screen. Many Unix commands read from `stdin` when no file is specified and write to `stdout`, allowing the output of one command to become the input of another. This design facilitates the chaining of commands (piping) to perform complex operations in a streamlined manner.\n\n-   **Input** generally refers to the data fed into a command, which can come from `stdin` or be specified as arguments.\n\n-   **Output** is the data produced by a command, displayed on `stdout` unless redirected.\n  \nThis interconnectivity of `stdin` and `stdout`, all communicating through text streams, exemplifies the efficiency and flexibility of Unix-like systems.\n\n::: \n\n::::\n\n\n\n\n\n## Text Manipulation \n\nText manipulation commands embody the Unix philosophy of '*do one thing and do it well*' and demonstrate the system’s power in processing text streams. This section will explore these fundamental commands, illustrating how they easily interact with text streams, standard input (`stdin`), and standard output (`stdout`) to perform complex text manipulations.\n\n### Wu-Tang\n\nThe `data/` folder contains three different file formats of the members of the [Wu-Tang American hip hop collective](https://en.wikipedia.org/wiki/Wu-Tang_Clan). We'll use the `tree` command to view the contents of the `data/` directory:[^tree]\n\n[^tree]: The `tree` command is not available in every Shell, but you can install it [using Homebrew](https://formulae.brew.sh/formula/tree).\n\n\n\n\n\n::: {.cell}\n\n```{.bash .cell-code}\ntree -P 'wu*' data\n```\n:::\n\n\n\n\n\nThe **`-P 'wu*'`** option tells `tree` to include only files and directories that match the pattern `'wu*'`. The pattern here uses a wildcard (`*`), meaning it will match any file or directory name that starts with `\"wu\"`. The pattern is case-sensitive by default.\n\n\n\n\n\n::: {.cell}\n\n```{.bash .cell-code}\n# data\n# ├── wu_tang.csv\n# ├── wu_tang.dat\n# ├── wu_tang.tsv\n# └── wu_tang.txt\n# \n# 1 directory, 4 files\n```\n:::\n\n\n\n\n\nWe can add the  **`-f`** option to instruct `tree` to display the full path for each file and directory relative to the root of the tree, instead of just showing the names. \n\n\n\n\n\n::: {.cell}\n\n```{.bash .cell-code}\ntree -Pf 'wu*' data\n```\n:::\n\n\n\n\n\nThe command summarizes the content by showing \"`1 directory, 4 files`\".[^tree-file-structure]\n\n\n\n\n\n::: {.cell}\n\n```{.bash .cell-code}\n# data\n# ├── data/wu_tang.csv\n# ├── data/wu_tang.dat\n# ├── data/wu_tang.tsv\n# └── data/wu_tang.txt\n# \n# 1 directory, 4 files\n```\n:::\n\n\n\n\n\n[^tree-file-structure]: **Note on Directory and File Structure:** The output structure from `tree -Pf 'wu*' data` visually shows that the `data` directory contains only the files matching the pattern and no subdirectories under it that match the pattern (or any subdirectories at all in this context). The `-P` option does not cause `tree` to exclude other directories from the inspection; it only filters what is displayed based on the pattern. If there were non-matching files or subdirectories, they would not appear in the output due to the filter.\n\nThe `wu_tang.dat` file contains the members in pipe-delimited format:\n\n\n\n\n\n::: {.cell}\n\n```{.bash .cell-code}\ncat data/wu_tang.dat\n# |Member           |Name                 |\n# |RZA              |Robert Diggs         |\n# |GZA              |Gary Grice           |\n# |Method Man       |Clifford Smith       |\n# |Raekwon the Chef |Corey Woods          |\n# |Ghostface Killah |Dennis Coles         |\n# |Inspectah Deck   |Jason Hunter         |\n# |U-God            |Lamont Hawkins       |\n# |Masta Killa      |Jamel Irief          |\n# |Cappadonna       |Darryl Hill          |\n# |Ol Dirty Bastard |Russell Tyrone Jones |\n```\n:::\n\n\n\n\n\n\nWe can use head and tail to view specific 'rows' of the data: \n\n\n\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nhead -n8 data/wu_tang.dat | tail -n4\n# |Raekwon the Chef |Corey Woods          |\n# |Ghostface Killah |Dennis Coles         |\n# |Inspectah Deck   |Jason Hunter         |\n# |U-God            |Lamont Hawkins       |\n```\n:::\n\n\n\n\n\n\n### Epigrams\n\n**<code>@sec-echo</code>** prints its arguments to the standard output (`stdout`). It can be used in scripts and on the command line to display messages or variables.\n\n\n\n\n\n::: {.cell}\n\n```{.bash .cell-code}\necho \"Beware of the Turing tar-pit in which everything is possible but nothing of interest is easy.\"\n# Beware of the Turing tar-pit in which everything is possible but nothing of interest is easy.\n```\n:::\n\n\n\n\n\n`echo` can also be used to write text to a file created with **<code>@sec-touch</code>**. The quote below comes from Alan Perlis's 1982 article, \"Epigrams on Programming.\"[^perlis-ref]\n\n[^perlis-ref]: Read the [Wikipedia](https://en.wikipedia.org/wiki/Epigrams_on_Programming) or download the [original PDF](https://iiif.library.cmu.edu/file/Simon_box00075_fld05959_bdl0003_doc0002/Simon_box00075_fld05959_bdl0003_doc0002.pdf).\n\n\n\n\n\n::: {.cell}\n\n```{.bash .cell-code}\ntouch data/turing_tarpit.txt\necho \"Beware of the Turing tar-pit in which everything is possible but nothing of interest is easy.\" > data/turing_tarpit.txt\n```\n:::\n\n\n\n\n\n**<code>@sec-cat</code>** displays the content of files straight to the screen, useful for checking what's in a file quickly.\n\n\n\n\n\n::: {.cell}\n\n```{.bash .cell-code}\ncat data/turing_tarpit.txt\n# Beware of the Turing tar-pit in which everything is possible but nothing of interest is easy.\n```\n:::\n\n\n\n\n\nAll 130 epigrams are stored and numbered in the `data/perlis_epigrams.txt` file.\n\n**<code>@sec-head</code>** and **<code>@sec-tail</code>** allow us to view the top and bottom of any text file: \n\n\n\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nhead data/ajperlis_epigrams.txt\n# One man’s constant is another man’s variable.\n# Functions delay binding; data structures induce binding. Moral: Structure data late in the programming process.\n# Syntactic sugar causes cancer of the semicolon.\n# Every program is a part of some other program and rarely fits.\n# If a program manipulates a large amount of data, it does so in a small number of ways.\n# Symmetry is a complexity-reducing concept (co-routines include subroutines); seek it everywhere.\n# It is easier to write an incorrect program than understand a correct one.\n# A programming language is low level when its programs require attention to the irrelevant.\n# It is better to have 100 functions operate on one data structure than 10 functions on 10 data structures.\n# Get into a rut early: Do the same process the same way. Accumulate idioms. Standardize. The only difference(!) between Shakespeare and you was the size of his idiom list - not the size of his vocabulary.\n```\n:::\n\n::: {.cell}\n\n```{.bash .cell-code}\ntail data/ajperlis_epigrams.txt\n# In seeking the unattainable, simplicity only gets in the way. If there are epigrams, there must be meta-epigrams.\n# Epigrams are interfaces across which appreciation and insight flow.\n# Epigrams parametrize auras.\n# Epigrams are macros, since they are executed at read time.\n# Epigrams crystallize incongruities.\n# Epigrams retrieve deep semantics from a data base that is all procedure.\n# Epigrams scorn detail and make a point: They are a superb high-level documentation.\n# Epigrams are more like vitamins than protein.\n# Epigrams have extremely low entropy.\n# The last epigram? Neither eat nor drink them, snuff epigrams.\n```\n:::\n\n\n\n\n\nApplying a 'trust, but verify' to the previous claim about the Turing tar-pit quote involves using **<code>@sec-grep</code>** (\"global regular expression print\") to confirm the text in `turing_tarpit.txt` is also in `dataperlis_epigrams.txt`.\n\n`grep` reads from `stdin` (or a list of files) and outputs the lines that match a specified pattern. Lets see how many epigrams in `data/perlis_epigrams.txt` include the word \"Turing\":\n\n\n\n\n\n::: {.cell}\n\n```{.bash .cell-code}\ngrep Turing data/ajperlis_epigrams.txt\n# Beware of the Turing tar-pit in which everything is possible but nothing of interest is easy.\n# What is the difference between a Turing machine and the modern computer? It’s the same as that between Hillary’s ascent of Everest and the establishment of a Hilton hotel on its peak.\n```\n:::\n\n\n\n\n\n#### Number sequences {#sec-num-seq}\n\nWe'll add numbers to each of the 130 epigrams in `data/ajperlis_epigrams.txt` to make them easier to reference. We can use the **<code>@sec-seq</code>** command piped into a formatting command like **<code>@sec-awk</code>**:\n\n\n\n\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nseq 130 | awk '{print $1\".\"}' | head\n# 1.\n# 2.\n# 3.\n# 4.\n# 5.\n# 6.\n# 7.\n# 8.\n# 9.\n# 10.\n```\n:::\n\n\n\n\n\n`seq 130` generates the sequence of numbers from 1 to 130, then `awk '{print $1\") \"}'` takes uses the numbers from `seq` as the input to `awk` (`$1`) and appends a period `.` to each number. We can add the `>` operator redirects the output to `data/numbered_lines.txt`.\n\n\n\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nseq 130 | awk '{print $1\".\"}' > data/numbered_lines.txt\n```\n:::\n\n\n\n\n\nWe can now use **<code>@sec-paste</code>** to combine `data/numbered_lines.txt` and `data/ajperlis_epigrams.txt`. The `-d` option stands is the delimiter to be placed between the pasted lines (which we'll use to specify a space `\" \"`).\n\nWe'll preview the head and tail of our paste before writing to a file:\n\n\n\n\n\n::: {.cell}\n\n```{.bash .cell-code}\npaste -d \" \" data/numbered_lines.txt data/ajperlis_epigrams.txt | head -n5\n# 1. One man’s constant is another man’s variable.\n# 2. Functions delay binding; data structures induce binding. Moral: Structure data late in the programming process.\n# 3. Syntactic sugar causes cancer of the semicolon.\n# 4. Every program is a part of some other program and rarely fits.\n# 5. If a program manipulates a large amount of data, it does so in a small number of ways.\n```\n:::\n\n::: {.cell}\n\n```{.bash .cell-code}\npaste -d \" \" data/numbered_lines.txt data/ajperlis_epigrams.txt | tail -n5\n# 126. Epigrams retrieve deep semantics from a data base that is all procedure.\n# 127. Epigrams scorn detail and make a point: They are a superb high-level documentation.\n# 128. Epigrams are more like vitamins than protein.\n# 129. Epigrams have extremely low entropy.\n# 130. The last epigram? Neither eat nor drink them, snuff epigrams.\n```\n:::\n\n\n\n\n\nAll 130 epigrams line up, so we'll assign the output to the `data/numbered_epigrams.txt` file.\n\n\n\n\n\n::: {.cell}\n\n```{.bash .cell-code}\npaste -d \" \" data/numbered_lines.txt data/ajperlis_epigrams.txt > \\\n  data/numbered_epigrams.txt\n```\n:::\n\n\n\n\n\nNow we can re-check our `Turing` pattern in `data/numbered_epigrams.txt`:\n\n\n\n\n\n::: {.cell}\n\n```{.bash .cell-code}\ngrep Turing data/numbered_epigrams.txt\n# 54. Beware of the Turing tar-pit in which everything is possible but nothing of interest is easy.\n# 83. What is the difference between a Turing machine and the modern computer? It’s the same as that between Hillary’s ascent of Everest and the establishment of a Hilton hotel on its peak.\n```\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n\n\n\n\n### Roxanne\n\nThe `data/roxanne.txt` file contains the lyrics to the 1979 song [Roxanne by The Police](https://en.wikipedia.org/wiki/Roxanne_(The_Police_song)). We'll use this file to explore several powerful Unix/Linux command-line utilities that are invaluable for searching, editing, and manipulating text data in files.\n\n#### Global substitutions {#sec-glob-sub}\n\n`awk` is a powerful text processing tool. Here's an example where `awk` uses `gsub` (global substitution) to replace the phrase \"red light\" with \"green light\" in the lyrics:\n\n\n\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nawk '{gsub(/red light/, \"green light\"); print}' \\\n  data/roxanne.txt | head -4\n# Roxanne\n# You don't have to put on the green light\n# Those days are over\n# You don't have to sell your body to the night\n```\n:::\n\n\n\n\n\n`gsub(/red light/, \"green light\")` tells `awk` to substitute `\"red light\"` with `\"green light\"` globally within each line. `print` outputs the modified line. Without this, `awk` would not display anything. The entire command is enclosed in single quotes to prevent the shell from interpreting any special characters.\n\nIf we wanted to replace `\"Roxanne\"` with `\"Dianne\"` throughout the song, we'd use:\n\n\n\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nsed 's/Roxanne/Dianne/g' data/roxanne.txt\n```\n:::\n\n::: {.cell}\n\n```{.bash .cell-code  code-fold=\"true\" code-summary=\"show/hide output\"}\n# Dianne\n# You don't have to put on the red light\n# Those days are over\n# You don't have to sell your body to the night\n# Dianne\n# You don't have to wear that dress tonight\n# Walk the streets for money\n# You don't care if it's wrong or if it's right\n# Dianne\n# You don't have to put on the red light\n# Dianne\n# You don't have to put on the red light\n# Dianne (Put on the red light)\n# Dianne (Put on the red light)\n# Dianne (Put on the red light)\n# Dianne (Put on the red light)\n# Dianne (Put on the red light)\n# Ro...\n# I loved you since I knew you\n# I wouldn't talk down to you\n# I have to tell you just how I feel\n# I won't share you with another boy\n# I know my mind is made up\n# So put away your make up\n# Told you once I won't tell you again\n# It's a bad way\n# Dianne\n# You don't have to put on the red light\n# Dianne\n# You don't have to put on the red light\n# Dianne (You don't have to put on the red light)\n# Dianne (Put on the red light)\n# Dianne (Put on the red light)\n# Dianne (Put on the red light)\n# Dianne (Put on the red light)\n# Dianne (Put on the red light)\n# Dianne (Put on the red light)\n# Dianne (Put on the red light)\n# Dianne (Put on the red light)\n# Dianne (Put on the red light)\n# Dianne (You don't have to put on the red light)\n# Dianne (Put on the red light)\n# Dianne (Put on the red light)\n# Dianne (Put on the red light)\n# Dianne (Put on the red light)\n```\n:::\n\n\n\n\n\nThe `s` stands for substitute, the pattern to be replaced (`\"Roxanne\"`) is followed by the new text (`\"Dianne\"`), and the `g` at the end of the command tells `sed` to perform the substitution globally on each line, rather than stopping after the first occurrence.\n\n`sort` arranges lines of text alphabetically or numerically and `uniq` filters out adjacent repeated lines in a file (often used in conjunction with `sort`). \n\n\n\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nsort data/roxanne.txt | uniq\n```\n:::\n\n::: {.cell}\n\n```{.bash .cell-code  code-fold=\"true\" code-summary=\"show/hide output\"}\n# I have to tell you just how I feel\n# I know my mind is made up\n# I loved you since I knew you\n# I won't share you with another boy\n# I wouldn't talk down to you\n# It's a bad way\n# Ro...\n# Roxanne\n# Roxanne (Put on the red light)\n# Roxanne (You don't have to put on the red light)\n# So put away your make up\n# Those days are over\n# Told you once I won't tell you again\n# Walk the streets for money\n# You don't care if it's wrong or if it's right\n# You don't have to put on the red light\n# You don't have to sell your body to the night\n# You don't have to wear that dress tonight\n```\n:::\n\n\n\n\n\n\nThe commands above sort the lines in the file first, then filter repeated lines.\n\nWe'll use `awk` to add line numbers to `data/roxanne.txt`. `NR` is the record number variable in `awk`, which counts the lines. `$0` represents the entire current line, and combining them with `print` will print the line number followed by the original line.\n\n\n\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nawk '{print NR, $0}' data/roxanne.txt > data/roxanne_lined.txt\nhead -n5 data/roxanne_lined.txt \n# 1 Roxanne\n# 2 You don't have to put on the red light\n# 3 Those days are over\n# 4 You don't have to sell your body to the night\n# 5 Roxanne\n```\n:::\n\n\n\n\n\n#### Two-file commands \n\nWe'll create a 'metadata' file for Roxanne in `data/roxanne_meta.txt` and add some content:\n\n\n\n\n\n::: {.cell}\n\n```{.bash .cell-code}\ntouch data/roxanne_meta.txt\necho \"1 <Song Title>\n2 <Chorus>\n3 <Verse 1>\n4 <Verse 2>\n5 <Song Title>\" > data/roxanne_meta.txt\ncat data/roxanne_meta.txt\n# 1 <Song Title>\n# 2 <Chorus>\n# 3 <Verse 1>\n# 4 <Verse 2>\n# 5 <Song Title>\n```\n:::\n\n\n\n\n\n`join` is used to combine two files based on a common field. Assuming there's another file with additional details for some lines, you would use:\n\n\n\n\n\n::: {.cell}\n\n```{.bash .cell-code}\njoin -1 1 -2 1 data/roxanne_lined.txt data/roxanne_meta.txt\n# 1 Roxanne <Song Title>\n# 2 You don't have to put on the red light <Chorus>\n# 3 Those days are over <Verse 1>\n# 4 You don't have to sell your body to the night <Verse 2>\n# 5 Roxanne <Song Title>\n```\n:::\n\n\n\n\n\n`-1 1` specifies that the join field for the *first* file (`data/roxanne_lined.txt`) is the *first* column, and `-2 1` means that the join field for the *second* file (`data/roxanne_meta.txt`) is also the *first* column.\n\n`comm` is used to compare two sorted files line by line and outputs three columns by default:  \n1. Lines unique to the first file.\n2. Lines unique to the second file.\n3. Lines common to both files.\n\nLet's assume we have two versions of the song \"Roxanne\". The original version is stored in `roxanne_orig.txt`, and a revised version with some lines changed, added, or removed is stored in `roxanne_rev.txt`.\n\n\n**roxanne_orig.txt**\n\n\n\n\n\n::: {.cell}\n\n```{.bash .cell-code}\ntouch data/roxanne_orig.txt\necho \"Roxanne\nYou don't have to put on the red light\nThose days are over\nYou don't have to sell your body to the night\" > data/roxanne_orig.txt\n```\n:::\n\n\n\n\n\n**roxanne_rev.txt**\n\n\n\n\n\n::: {.cell}\n\n```{.bash .cell-code}\ntouch data/roxanne_rev.txt\necho \"Roxanne\nYou don't have to put on the green light\nThose days are over\nYou don't need to sell your dreams to the night\" > data/roxanne_rev.txt\n```\n:::\n\n\n\n\n\nThese files are structured to have similar content with *minor* differences.\n\n:::{layout=\"[50,50]\" layout-valign=\"top\"}\n\n```bash\n# Roxanne\n# You don't have to put on the red light\n# Those days are over\n# You don't have to sell your body to the night\n```\n\n```bash\n# Roxanne\n# You don't have to put on the green light\n# Those days are over\n# You don't need to sell your dreams to the night\n```\n\n:::\n\nFirst, ensure both files are sorted (if not already). For simplicity, let's assume these are sorted or have matching line orders. Then, use `comm`:\n\n\n\n\n\n::: {.cell}\n\n```{.bash .cell-code}\ncomm data/roxanne_orig.txt data/roxanne_rev.txt\n# \t\tRoxanne\n# \tYou don't have to put on the green light\n# \tThose days are over\n# You don't have to put on the red light\n# Those days are over\n# You don't have to sell your body to the night\n# \tYou don't need to sell your dreams to the night\n```\n:::\n\n\n\n\n\n**Output:**\n\n- The first column shows lines that are only in the original file (`roxanne_orig.txt`).\n\n![](img/comm1.png){width='85%' fig-align='center'}\n    \n- The second column shows lines that are only in the revised file (`roxanne_rev.txt`).\n\n![](img/comm2.png){width='85%' fig-align='center'}\n    \n- The third column shows lines that are common in both files.\n\n![](img/comm3.png){width='85%' fig-align='center'}\n\nWe can suppress any of these columns using the `-1`, `-2`, or `-3` options. For example, `comm -12 data/roxanne_orig.txt data/roxanne_rev.txt` will show only the lines that are common in both files:\n\n\n\n\n\n::: {.cell}\n\n```{.bash .cell-code}\ncomm -12 data/roxanne_orig.txt data/roxanne_rev.txt\n# Roxanne\n```\n:::\n\n\n\n\n\nOr \n\n\n\n\n\n::: {.cell}\n\n```{.bash .cell-code}\ncomm -1 -2 data/roxanne_orig.txt data/roxanne_rev.txt\n# Roxanne\n```\n:::\n\n\n\n\n\n**NOTE**: ensure the files are sorted on the lines you are comparing; otherwise, `comm` will not function correctly.\n\nTo see the line by line differences between `data/roxanne_orig.txt` and `data/roxanne_rev.txt`, pass both files to `diff`:\n\n\n\n\n\n::: {.cell}\n\n```{.bash .cell-code}\ndiff data/roxanne_orig.txt data/roxanne_rev.txt\n# 2c2\n# < You don't have to put on the red light\n# ---\n# > You don't have to put on the green light\n# 4c4\n# < You don't have to sell your body to the night\n# ---\n# > You don't need to sell your dreams to the night\n```\n:::\n\n\n\n\n\nThe output of differences from `diff` can be interpreted as follow: \n\n1. `2c2` indicates that a change has been made at line `2` of both files. The `c` stands for \"change\".\n    -   `< You don't have to put on the red light` shows what line 2 looked like in the original file (`roxanne_orig.txt`)\n    -   `---` is a separator used by `diff` to distinguish between the old version and the new version of the line\n    -   `> You don't have to put on the green light`: shows what line 2 now looks like in the revised file (`roxanne_rev.txt`)\n\n2. `4c4` indicates a change at line `4` in both documents.\n    -   `< You don't have to sell your body to the night` shows the original text at line 4 in `roxanne_orig.txt`\n    -   `---`: Again, a separator\n    -   `> You don't need to sell your dreams to the night` shows the revised text at line 4 in `roxanne_rev.txt`\n\nThe `-y` option will display the changes side-by-side \n\n\n\n\n\n::: {.cell}\n\n```{.bash .cell-code .code-overflow-scroll}\ndiff -y data/roxanne_orig.txt data/roxanne_rev.txt\n# Roxanne                                                                 Roxanne\n# You don't have to put on the red light                          |       You don't have to put on the green light\n# Those days are over                                                     Those days are over\n# You don't have to sell your body to the night                   |       You don't need to sell your dreams to the night\n```\n:::\n\n\n\n\n\nOr, if all we care about is *if* the files differ, we can use the `-q` option:\n\n\n\n\n\n::: {.cell}\n\n```{.bash .cell-code}\ndiff -q data/roxanne_orig.txt data/roxanne_rev.txt\n# Files data/roxanne_orig.txt and data/roxanne_rev.txt differ\n```\n:::\n\n\n\n\n\n<!--\n\n`wc` (word count) counts lines, words, and characters in a file. To count these in the lyrics file:\n\n\n\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nwc data/roxanne.txt\n```\n:::\n\n\n\n\n\n`xargs` builds and executes command lines from standard input (`stdin`). It's most often used in combination with other commands through pipes. `xargs` takes input from a pipe and passes it as arguments to another command, allowing for powerful command-line operations that process a list of inputs iteratively.\n\n-->\n\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n\n## Recap \n\nUsing these commands can dramatically enhance productivity and efficiency when working with text files in Unix/Linux environments.\n\n\n\n\n\n\n:::: {.callout-note collapse='false' appearance='default' icon=false}\n\n## [See a typo, error, or something missing?]{style='font-weight: bold; font-size: 0.95em;'}\n\n::: {style='font-size: 0.90em; color: #282b2d;'}\n\n\nPlease open an issue on [GitHub.](https://github.com/mjfrigaard/fm-unix/issues/new)\n\n::: \n\n::::",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}